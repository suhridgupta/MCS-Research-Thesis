\clearpage

\def\chaptertitle{Literature Review}

\lhead{\emph{\chaptertitle}}

\chapter{\chaptertitle}
\label{ch:lit-review}

In this chapter, we discuss some of the common implementation strategies for edge computing paradigms in Section~\ref{sec:ch3-edge-implementation} before discussing the inherent challenges and limitations in Section~\ref{sec:ch3-edge-issues}. Then in Section~\ref{sec:ch3-resource-schedule-solutions} we review the resource scheduling solutions which attempted to resolve these challenges. Building on this foundation, \cref{sec:ch3-reactive-solutions,sec:ch3-proactive-solutions,sec:ch3-hybrid-solutions} comprise of a detailed literature review of the state-of-the-art auto-scaling algorithms used to mitigate these challenges, and a comparison of their performances and drawbacks.

\section{Edge Computing Implementation}
\label{sec:ch3-edge-implementation}

Yu \textit{et al}.~\cite{yu2017survey} states when implementing edge computing architectures, researchers typically focus on two models, namely the hierarchical model, and the software-defined model.\par

\subsection{Hierarchical Model}
\label{subsec:ch3-hierarchical-model}

Since edge and cloud servers are deployed at varied distances from the end users, it makes sense that the edge architecture is to be divided into such a hierarchy, with each layer defining the functions relative to resource availability and distance.\par

Tong \textit{et al}.~\cite{tong2016hierarchical} give an overview of such a hierarchical model. The bottom tier is usually comprised of a geo-distributed servers which receive workload from mobile devices via wireless links. These servers are then connected to a higher tier level of servers which comprise of the remote data centers. If the mobile workload received by a lower tier server exceeds its computational capacity, it can offload this excess workload to a higher tier server. In this way, the architecture can serve large load peaks.\par

Several research efforts exist for such a model. Tong \textit{et al}.~\cite{tong2016hierarchical} proposed an edge cloud hierarchy which could be used to serve high load demands from mobile users. In such a model, the cloudlet servers were deployed at the edge layer, while the cloud established as a tree hierarchy. By using such an implementation, the edge layer was able to aggregate its servers resource abilities to better serve peak workloads.\par

Jarwah \textit{et al}.~\cite{jararweh2016future} demonstrated a similar approach to a hierarchical model, which integrated Mobile Edge Computers (MEC) servers and cloudlets. The mobile users obtained specific services as per requested, and the MEC served the ability to deliver their computational and storage requirements.\par

\subsection{Software-defined Model}
\label{subsec:ch3-software-defined-model}

The number of end users and devices which connect to the edge architecture typically numbers in the millions~\cite{yu2017survey}. Thus, management of an application deployed on this architecture can prove to be significantly challenging. To address these complexities, Software Defined Networks (SDN) were proposed.\par

According to Wang \textit{et al}.~\cite{wang2017controller}, SDNs distinguish themselves from conventional networking approaches by decoupling the control plane from the data plane. The control plane is constructed using a combination of dedicated controllers. These serve as the control center of the SDN model, while the data-plane simply forwards data packets in the form of a network switch. Such a decoupling makes the architecture highly flexible, as well as simplifies network management~\cite{liu2015device}. However they have drawbacks which include performance issues if not developed properly.\par

Despite these challenges, there have been a number of research efforts based on the SDN model. Du and Nakao~\cite{du2016application} presented an MEC model which was application specific. In this model, the software-defined data plane acts as a Mobile Virtual Network Operator (MVNO). The mechanism computes a hop-count based tethering as well as optimizes the process.  Fairness among determining user resources is determined through regulating concurrent TCP connections.\par

Similarly, Jaraweh \textit{et al}.~\cite{jararweh2016sdmec} proposed an SDN model which integrated its capabilities to the MEC system. The management and administrative requirements for the entire model could be reduced in this manner.\par

Finally, Salman \textit{et al}.~\cite{salman2015edge} demonstrated an integration of SDN, MEC, and a Network Function Virtualization (NFV)m which was capable of achieving better MEC performance in mobile networks than the other two works. Such a model could be further extended to enable an IOT-capable deployment.\par

\section{Edge Computing Issues and Challenges}
\label{sec:ch3-edge-issues}

\subsection{Resource Allocation}
\label{subsec:ch3-edge-resource-alloc}

Cao \textit{et al}.~\cite{cao2020overview} demonstrated the key differentiations traditional cloud computing architectures have compared to edge architectures, while asserting that edge deployments remain an extension of the cloud. The aim of cloud computing infrastructures is to process huge amounts of data from multi-regional zones, or in the best case, globally. This is done so as to perform in-depth analysis in diverse fields such as health-care, robotics, and business decision making. Traditionally, they also dealt with non-real-time data for decision-making~\cite{premsankar2018edge}. On the other hand, edge computing usually handles smaller scale data, locally clustered and isolated in separate zones, and highly real-time in nature~\cite{mishra2020early}. The data processed in traditional cloud computing environments are also generally done using a high network bandwidth. This is due to the large distances data needs to be transmitted over to reach the data centres and cloud servers. Such data transmission places an enormous burden on the cloud network, and poses multiple security challenges in ensuring that the data is not compromised in transit.\par

The real-time nature of edge computing applications necessitates a method of resource allocation which ensures minimal cost of deployment, and maximum efficiency in terms of performance. As mentioned in Section~\ref{sec:ch1-edge-arch}, micro-service container orchestration technologies are leveraged to achieve these aims. Kristiani \textit{et al}.~\cite{kristiani2019} demonstrated an edge computing architecture, where the edge layer consists of Kubernetes nodes. Such a deployment increases the scalability, as well as maintains the ease of deployment, upgrade, and removal of nodes in the edge layer. Scaling of resources through the means of auto-scaling depending on the resource requirements is crucial to the architecture's performance. Default solutions such as the inbuilt autoscaler provided by Kubernetes, while generally useful for cloud applications, are unsuitable for edge architectures according to Phan \textit{et al}.~\cite{phan2022traffic}. They note that due to the algorithm's default nature to allocate resources in a round-robin manner, they do not take into account which Kubernetes nodes require priority resources allocation, violating edge architecture paradigms.

\subsection{Cold start problem}
\label{subsec:ch3-cold-start}

To explain the cold start problem, we use the example of horizontal pod auto-scaling in Kubernetes. When the control plane requests for a deployment replica to be scaled up, Kubernetes adds more pods to the data plane nodes.  Based on the internal workload, the pod needs to be elastically scaled out~\cite{beni2021reducing}. Even though the pod start up time is significantly quicker than, say, a traditional virtual machine, there is a latency inherent to bootstrapping the container, preparing the pod environment based on the deployment specification, and initialising the code present in the container image, and registering the pod in a ``ready'' state to the Kubernetes control plane.\par

Several techniques exist to mitigate this resource latency. The Kubernetes container runtime uses snapshots~\cite{cadden2019seuss}, lazy fetching of container images~\cite{lorenzo2019fogdocker}, and container queues~\cite{lin2019mitigating}. However, these measures do not eliminate the issue of the inherent latency in installing and registering the resource. Due to this, researchers looked into scaling resources in a predictive manner, so as to ensure the micro-service application has enough time to spool up resources before the actual demand comes in. This process, by which resources are created and registered with the container orchestration before the expected workload is known as resource \textit{cold start}.\par

\subsection{SLA Guarantees}
\label{subsec:ch3-sla-edge}

There are several challenges posed in providing SLA guarantees in an edge deployment:
\begin{itemize}
    \item Users queueing for large periods of time to use a service~\cite{venticinque2011cloud}.
    \item Degradation of application performance due to peak levels of workload, leading to user dissatisfaction~\cite{sakr2012sla}.
    \item Incorrect resources being allocated to the application, leading to either a degradation of availability, or large cost of application deployment~\cite{houlihan2014auditing}.
\end{itemize}

Several strategies have been proposed to counteract these challenges. Linlin \textit{et al}.~\cite{wu2013sla} proposed a customer-driven strategy  to minimize the provisioning costs. The algorithm considers the customer profiles as well as cloud providers' quality parameters such as response time to dynamically handle customer requests. Rajkumar \textit{et al}.~\cite{rajavel2012achieving} proposed a solution for alleviating the issue of delay in service allocation to users through the use of a novel hierarchical scheduling algorithm. This algorithm increases the performance of the scheduling algorithm, thus reducing the wastage of resources, and minimizing wait times. Sakr \textit{et al}.~\cite{sakr2012sla} introduced a novel approach to combat application performance degradation by using a middleware between consumers and the cloud. This middleware helps to facilitate dynamic provisioning of cloud databases based on consumer requirements, tailoring their needs and requirements to mitigate peak usages being hit often.

\section{Scheduling Strategies}
\label{sec:ch3-resource-schedule-solutions}

To counteract the limitations discussed in Section~\ref{subsec:ch3-edge-resource-alloc}, several custom scheduling and resource management algorithms have been proposed for edge architectures.\par

Skarlat \textit{et al}.~\cite{skarlat2016resource} demonstrated an algorithm for resource scheduling where the usage of resources was formalized as an optimization problem. Thus, the authors attempted to minimize the network delay when requesting computational resources. Based on this work, Aazam and Huh~\cite{aazam2015dynamic} proposed another solution for resource management which attempted to estimate the resources per service required, based on the user's previous behaviour as well as type of service being requested. By following such an approach, the resource wastage was actively reduced in edge nodes. Another resource allocation solution provided by Ni \textit{et al}.~\cite{ni2017resource} was based on priced timed Petri nets. The resources in the edge nodes are divided into several groups. The users can then select resources as per their requirements in an autonomous manner according to the price and time-cost of the operation.\par

Based on these initial proposals, Nguyen \textit{et al}.~\cite{nguyen2020elasticfog} revealed ElasticFog, a resource provisioning algorithm which operates on top of the Kubernetes architecture. The algorithm provides real-time elastic scheduling for the resources on the edge nodes by monitoring the traffic distribution on the network, thereby achieving a significantly higher throughput and network efficiency in comparison to the default Kubernetes scheduler solution.\par

Wojciechowski \textit{et al}.~\cite{wojciechowski2021netmarks} proposed a similar extension to the Kubernetes scheduler which deployed traffic-aware provisioning of resources. The extension worked alongside the Istio Service Mesh~\footnote{\url{https://istio.io/latest/about/service-mesh/}} to collect dynamic network metrics for the scheduling of resources. The algorithm was shown to have highly efficient uses for edge deployments such as the 5G network.\par

While these proposals improved the scheduling and resource provisioning of edge deployments, they did not address key limitations addressed above such as the need for dynamic resource scaling so as to face the challenges of real-time data processing and SLA compliance. Due to these issues, several auto-scaling algorithms extending the design principles of these resource scheduling algorithms were proposed to address them.

\section{Reactive Auto-scaling Strategies}
\label{sec:ch3-reactive-solutions}

%TC:ignore
\begin{table}
    \caption{Summary of reactive auto-scaling solutions}\label{tab:reactive-autoscalers}
    \centering
    \begin{tabular}{ ccccccccc }
         \toprule
         \multirow{2}{*}{\textbf{Features}}&\multicolumn{8}{c}{\textbf{Reactive algorithms}}\\
         \cmidrule{2-9}
         &\cite{phan2022traffic}&\cite{kampars2017auto}&\cite{zhang2019quantifying}&\cite{srirama2020application}&\cite{hoenisch2015four}&\cite{santos2020qoe}&\cite{sheganaku2023cost}&\cite{taherizadeh2019dynamic}\\
         \midrule
         \multicolumn{1}{r}{Simple deployment} & \cmark & \xmark & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark\\
         \multicolumn{1}{r}{Simple parameter tuning} & \cmark & \xmark & \cmark & \xmark & \cmark & \cmark & \cmark & \xmark\\
         \multicolumn{1}{r}{Custom metrics} & \xmark & \xmark & \xmark & \xmark & \xmark & \cmark & \cmark & \xmark\\
         \multicolumn{1}{r}{Light-weight deployment} & \cmark & \cmark & \cmark & \cmark & \xmark & \xmark & \xmark & \cmark\\
         \multicolumn{1}{r}{Edge architecture compliant} & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark & \cmark\\
         \multicolumn{1}{r}{SLA-compliant} & \xmark & \xmark & \xmark & \xmark & \xmark & \xmark & \xmark & \xmark\\
         \multicolumn{1}{r}{Minimizes deployment cost} &  \xmark & \xmark & \xmark & \xmark & \xmark & \xmark & \xmark & \xmark\\
         \toprule
    \end{tabular}
\end{table}
%TC:endignore

Nunes \textit{et al}.~\cite{nunes2021state} stated that horizontal pod auto-scaling using a reactive strategy remains the most popular auto-scaling technique, as well as research topic. These strategies, despite having limitations such as a reliance on predetermined resource thresholds and a delay in resource scaling, have been popular in research articles.  Dogani \textit{et al}.~\cite{dogani2023auto} stated that this was due to the simplicity and user-friendliness in developing them. Table~\ref{tab:reactive-autoscalers} summarizes the reactive auto-scaling algorithms discussed below:\par

Kampars and Pinka~\cite{kampars2017auto} proposed a reactive auto-scaling algorithm for edge architectures based on open-source technologies. The algorithm scales in a non-standard approach, considering real-time adjustments in the application logic to determine the strategy of scaling, resulting in several improvements in performance. This logic however is complex, while the challenging metric selection and integration procedure make it unsuitable for deployment on an edge architecture.\par

Zhang \textit{et al}.~\cite{zhang2019quantifying} presented an algorithm for determining edge elasticity through container-based auto-scaling. The authors posit that elasticity is a key factor of how an edge deployment as well as the lightweight containers which make up the edge layer perform. The framework not only autoscales container resources, but also monitors resource usage. They were able to show experimentally that to balance system stability with a decent elasticity required careful tuning of parameters such as the cooldown periods of scaling. However the lack of addressal of the cold start problem discussed above results in a delay in scaling resources, violating SLA-compliance.\par

Srirama \textit{et al}.~\cite{srirama2020application} investigated an container-aware auto-scaling solution which deploys applications to containers which it deems ``best-fit''. The algorithm also uses a rule-based policy to minimize the deployment time, thus mitigating the issue of cold-start. Finally, a dynamic bin-packing sub-algorithm ensures that the applications are deployed on the least required physical servers, thus minimizing wastage of computing resources. The authors experimentally demonstrated that this algorithm minimized  the processing time, cost, and resource utilization. However the complex and user-intensive parameter tuning make it difficult to adapt to generalized use-cases.\par

Hoenisch \textit{et al}.~\cite{hoenisch2015four} implemented a four-fold auto-scaling strategy for containerised applications which asks if the containers or servers can be autoscaled horizontally or vertically. This question is formalized as a multi-objective optimization problem, and the approach used reduced the cost of each request by more than 20\%. The drawback is the heavy performance and resource overhead when running in edge deployments, leading to a degredation in application performance.\par

Santos \textit{et al}.~\cite{santos2020qoe} implemented a quality of experience based auto-scaling of containerized edge deployments. The algorithm can autoscale both horizontally and vertically on a set of quality metrics which can be customized by the end-user. While the authors explained that the experimental results displayed a performance comparable to other reactive solutions, further research demonstrated that the algorithm is unable to scale well on highly dynamic workloads.\par

Sheganaku \textit{et al}.~\cite{sheganaku2023cost} devised an container-based auto-scaling solution which allocates resources in a four-fold manner similar to Hoenisch \textit{et al}.~\cite{hoenisch2015four}. The authors formulated the problem as a multi-objective optimization problem and applied a Mixed-Integer Linear Programming (MILP) approach to allocate resources to containers. Such an approach demonstratively reduced costs while maintaining SLA constraints. However, this came at a cost as the solution is too time consuming and computationally expensive for edge deployments.\par

Taherizadeh and Stankovski~\cite{taherizadeh2019dynamic} proposed a multi-level auto-scaling solution using a rule-based approach. The algorithm uses dynamically changing thresholds based on both the container infrastructure as well as application, resulting in improved performance as compared to other reactive approaches, however such a multi-level solution is difficult to tune and optimize, making it unsuitable for dynamic and custom workloads.\par

Phan \textit{et al}.~\cite{phan2022traffic} proposed a reactive auto-scaling solution for edge deployments for IoT devices which dynamically allocates resources based on incoming traffic. This traffic-aware horizontal pod autoscaler (THPA) operates on top of the underlying Kubernetes architecture. As discussed above, the default Kubernetes horizontal pod autoscaler scales resources in a round-robin manner, not taking into context which nodes are receiving the highest resource requests. THPA alleviates this issue by modelling the resource requests per Kubernetes nodes. It then intelligently allocates pods to the nodes with higher number of requests. The authors were able to experimentally demonstrate that following such an approach provided a 150\% improvement in response time and throughput. However the algorithm is not SLA compliant due to the delay in scaling resources in a reactive manner.

\section{Proactive Auto-scaling Strategies}
\label{sec:ch3-proactive-solutions}

%TC:ignore
\begin{table}
    \caption{Summary of proactive auto-scaling solutions}\label{tab:proactive-autoscalers}
    \centering
    \begin{tabular}{ ccccccc }
         \toprule
         \multirow{2}{*}{\textbf{Features}}&\multicolumn{6}{c}{\textbf{Proactive algorithms}}\\
         \cmidrule{2-7}
         &\cite{ju2021proactive}&\cite{meng2016crupa}&\cite{imdoukh2020machine}&\cite{messias2016combining}&\cite{abdullah2020burst}&\cite{alidoost2023introducing}\\
         \midrule
         \multicolumn{1}{r}{Simple deployment} &            \xmark & \cmark & \cmark & \cmark & \cmark & \cmark\\
         \multicolumn{1}{r}{Simple parameter tuning} &      \xmark & \xmark & \xmark & \cmark & \xmark & \xmark\\
         \multicolumn{1}{r}{Custom metrics} &               \cmark & \cmark & \xmark & \xmark & \xmark & \xmark\\
         \multicolumn{1}{r}{Light-weight deployment} &      \xmark & \xmark & \xmark & \cmark & \xmark & \xmark\\
         \multicolumn{1}{r}{Edge architecture compliant} &  \cmark & \xmark & \xmark & \xmark & \xmark & \xmark\\
         \multicolumn{1}{r}{SLA-compliant} &                \xmark & \cmark & \cmark & \cmark & \xmark & \xmark\\
         \multicolumn{1}{r}{Minimizes deployment cost} &    \xmark & \xmark & \cmark & \xmark & \xmark & \xmark\\
         \toprule
    \end{tabular}
\end{table}
%TC:endignore

Lorido \textit{et al}.~\cite{lorido2014review} showed that compared to reactive algorithms, proactive algorithms achieved better resource allocation once they had been carefully optimized. Machine learning (ML) techniques such as auto-regressive integrated moving averages (ARIMA) and long short-term memory (LSTM) have gained populary in time-series analysis due to their relative ease of building and efficiency compared to other ML models. Through the careful use of these models, linear patterns in the data can be automatically identified in a short amount of time with relatively constrained resources. There are however several challenges when implementing a proactive algorithm. Time-series analysis models may struggle when dealing with highly complex and non-linear data~\cite{dogani2023auto}. The development of a generalised algorithm for several edge architectures remains a costly process. One of the biggest challenges is the initial lack of training data. Another issue is the exploding or vanishing gradient problem~\cite{pascanu2013difficulty}, though modern algorithms ensure that they avoid this pitfall~\cite{hochreiter2001gradient}. Despite these challenges, their application in scaling of resources with semi-predictable data series remain valuable. Table~\ref{tab:proactive-autoscalers} summarizes the proactive auto-scaling algorithms discussed below:\par

Ju \textit{et al}.~\cite{ju2021proactive} presented a proactive horizontal pod auto-scaling solution for edge computing paradigms. The algorithm, known as Proactive Pod Autoscaler (PPA) was designed to predict resource requests on multiple user-defined metrics, such as CPU request and I/O traffic requests. The algorithm does not use any specific machine learning model for the time-series analysis, instead the model is to be inputted by the user. This model agnostic architecture allows for a very high level of customization. The user can deploy an ARIMA, LSTM, or even Bayesian confidence models. In a confidence model, the autoscaler will only deploy resources if the confidence value is seen to be above a specified user-defined threshold. The authors validated their findings by testing the architecture using LSTM and ARIMA models, the results concluded that this algorithm significantly outperformed both the default Kubernetes autoscaler, as well as existing reactive auto-scaling solutions. However, such customizability leads to a complex deployment and hyper-parameter tuning process. This, along with a lack of initial training data causes erroneous predictions before the model corrects itself.\par

Meng \textit{et al}.~\cite{meng2016crupa} created a proactive auto-scaling algorithm for forecasting the Kubernetes CPU usage of containers using a time-series prediction. They achieved this using the ARIMA model. The time-series was split into a training and validation set using a 5:1 ratio before being passed to the deep learning model. The authors were able to demonstrate experimentally that such an architecture reduced the forecast errors to 6.5\%, as compared to the baseline of 17\%. This showed a high prediction accuracy, however the cost of training this model was prohibitively high, making it unsuitable for edge deployments.\par

Imdoukh \textit{et al}.~\cite{imdoukh2020machine} proposed a proactive auto-scaling solution using an LSTM model, designed for edge computing architectures. The algorithm uses an LSTM neural network to predict future network traffic workload to determine the resources to assign to edge nodes ahead of time (cold-start). The authors experimentally demonstrated that their algorithm was as accurate as existing ARIMA-based proactive solutions, but theirs significantly reduced the prediction time, as well as computed the minimum resource allocation required to handle future workload. However, this algorithm also suffers from the problems related to a lack of initial training data encountered by Ju \textit{et al}.~\cite{ju2021proactive}\par

Messias \textit{et al}.~\cite{messias2016combining} created a proactive autoscaler using genetic algorithms (GA). The genetic algorithm combines several time-series forecasting models, while having the benefit of not requiring a training phase as the model adapts to the incoming data. The experimental results concluded that this approach produces results comparable to several state-of-the-art proactive models, and can adapt to various time series models. The initial state of the genetic algorithm is however set randomly~\cite{lambora2019genetic}, this causes the initial forecasting to contain a significant amount of errors, and the algorithm can take an arbitrarily large amount of time to converge to an acceptable forecast result.\par

Abdulla \textit{et al}.~\cite{abdullah2020burst} devised an auto-scaling solution which is capable of detecting sudden bursts in dynamic workloads. The algorithm achieves this through a method of workload and resource prediction to make a scaling decision. Experimenting on several burst-heavy workloads, the autoscaler demonstrated significant improvements compared to other state-of-the-art methods. The XGBoost algorithm used to forecast these burts is quite rigid however, and thus is incapable of capturing several other workload patterns.\par

Alidoost \textit{et al}.~\cite{alidoost2023introducing} proposed a workload classification model using a Support Vector Machine (SVM). The algorithm extracts the user's workload characteristics, and then trains the SVM on it. The authors demonstrated a 10\% forecast error reduction compared to other machine learning proactive forecast approaches. The SVM however struggles to identify boundaries for complex data, making this algorithm unsuitable for non-linear workload patterns.\par

\section{Hybrid Auto-scaling Strategies}
\label{sec:ch3-hybrid-solutions}

%TC:ignore
\begin{table}
    \caption{Summary of hybrid auto-scaling solutions}\label{tab:hybrid-autoscalers}
    \centering
    \begin{tabular}{ ccccccc }
         \toprule
         \multirow{2}{*}{\textbf{Features}}&\multicolumn{5}{c}{\textbf{Hybrid algorithms}}&\multirow{2}{*}{\textbf{Proposed solution}}\\
         \cmidrule{2-6}
         &\cite{xu2007use}&\cite{lama2009efficient}&\cite{ramperez2021flas}&\cite{biswas2017hybrid}&\cite{singh2021rhas}&\\
         \midrule
         \multicolumn{1}{r}{Simple deployment} &            \cmark & \cmark & \cmark & \cmark & \cmark & \cmark\\
         \multicolumn{1}{r}{Simple parameter tuning} &      \cmark & \cmark & \cmark & \xmark & \xmark & \cmark\\
         \multicolumn{1}{r}{Custom metrics} &               \cmark & \xmark & \xmark & \cmark & \cmark & \cmark\\
         \multicolumn{1}{r}{Light-weight deployment} &      \cmark & \xmark & \cmark & \xmark & \xmark & \cmark\\
         \multicolumn{1}{r}{Edge architecture compliant} &  \xmark & \xmark & \xmark & \xmark & \xmark & \cmark\\
         \multicolumn{1}{r}{SLA-compliant} &                \xmark & \xmark & \cmark & \cmark & \cmark & \cmark\\
         \multicolumn{1}{r}{Minimizes deployment cost} &    \xmark & \xmark & \xmark & \xmark & \cmark & \cmark\\
         \toprule
    \end{tabular}
\end{table}
%TC:endignore

All the approaches mentioned in \cref{sec:ch3-reactive-solutions,sec:ch3-proactive-solutions} have their benefits and drawbacks. Thus, hybrid solutions which merge multiple auto-scaling methods were proposed~\cite{qu2018auto}. While hybrid algorithms for cloud-based deployments exist, integrating them into edge architectures pose several challenges due to the lower data storage and computational capacity of the edge layer. Furthermore, extracting the proactive time-series analysis to the cloud layer poses further challenges due to the inherent latency present between the two layers. Despite this, exploring these solutions provides a solid template for the approach used in this paper, Table~\ref{tab:hybrid-autoscalers} shows an overview of the proposals discussed below:\par

In 2007, one of the first hybrid algorithms for a distributed deployment was proposed by Jing \textit{et al}.~\cite{xu2007use}. This algorithm combined rule-based fuzzy inference with machine learning forecasting for dynamic resource allocation. The authors experimentally verified their algorithm through a prototype to demonstrate that it can reduce the resource consumption on resource management systems compared to their default resource allocation algorithms.\par

Based on this work, Lama and Zhou~\cite{lama2009efficient} proposed a resource provisioning algorithm for multi-cluster set ups using a hybrid autoscaler. The autoscaler comprised of a combination of fixed fuzzy rule-based logic and a self adaptive algorithm which dynamically tuned the scaling factor. The authors tested this algorithm on a simulation to demonstrate performance benefits compared to existing approaches. This however was a limited experiment, not comprising of tests on a production environment.\par

A hybrid approach for cloud computing architectures was proposed by Ramp{\'e}rez \textit{et al}.~\cite{ramperez2021flas}. The algorithm which was called Forecasted Load Auto-scaling (FLAS), combines a predictive model for forecasting time-series resources, while the reactive model estimates other high-level metrics and delegates for the proactive model, reducing the potential forecast error when encountering previously unseen workloads. The approach was shown to demonstrate efficient resource allocation as compared to other state-of-the-art solutions. FThe linear regression forecaster was however too simplistic to predict complex time-series, leading to erroneous results.\par

Biswas \textit{et al}.~\cite{biswas2017hybrid} presented a hybrid algorithm designed for cloud computing deployments with service level agreements. The proactive algorithm involves a machine-learning based approach using an SVM model, alongside the reactive algorithm to dynamically allocate resources. The algorithm was experimentally shown to perform better than a pure reactive or proactive solution in most cases. Such an SVM-based model is expensive to train however, making it infeasible to deploy on edge deployments due to the resource and latency constraints discussed above.\par

Finally, another cloud computing based autoscaler with SLA-constraints was proposed by Singh \textit{et al}.~\cite{singh2021rhas}. The robust hybrid autoscaler (RHAS) was designed particularly for web applications. The reactive rule-based autoscaler deals with current workload requirements, while the proactive model attempts to predict incoming resource workloads. The proactive forecaster uses a modification of the ARIMA machine learning model, known as the Technocrat ARIMA and SVR Model (TASM)~\cite{singh2019tasm}. The authors tested their algorithm on two data-sets belonging to ClarkNet and NASA. The technique was demonstrated to both reduce cloud deployment cost and SLA violations while giving consistent CPU utilization. However, the TASM forecaster was too complex and resource intensive to be deployed on a scarce resource padadigm such as the edge layer. This resource intensiveness increased the training times drastically too, making it infeasible for conforming to SLA constraints on an edge architecture paradigm.\par

The above algorithm by Singh \textit{et al}.~\cite{singh2021rhas} provided the best approach to be used when creating a hybrid autoscaler. Therefore, while implementing the autoscaler presented in this thesis, the generalized architecture of the RHAS deployment was further extended to streamline both the reactive and proactive autoscalers, while choosing a more efficient and cost-effective forecasting model so as to make it SLA-compliant on edge architectures, and eliminating the costly and time-consuming hyper-parameter tuning process.\par
